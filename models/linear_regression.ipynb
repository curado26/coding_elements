{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Question: Write code to implement linear regression from scratch without using\n",
    "any machine learning libraries like scikit-learn.\n",
    "\n",
    "Answer Guidance: Be prepared to:\n",
    "* Handle data input and preprocessing.\n",
    "* Compute the OLS estimates manually.\n",
    "* Implement matrix operations using libraries like NumPy.\n",
    "* Optionally, write functions to predict new data points and calculate metrics \n",
    " like Mean Squared Error (MSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalizing for Multiple Linear Regression\n",
    "\n",
    "def multiple_linear_regression(X,y):\n",
    "\n",
    "    \"\"\"\n",
    "    Estimates the coefficients for a multiple linear regression model using the normal equation.\n",
    "\n",
    "    This function computes the coefficients (weights) for a multiple linear regression model\n",
    "    by solving the normal equation: beta = (X^T * X)^(-1) * X^T * y. It works for any number\n",
    "    of predictors (independent variables) and includes an intercept term.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : array-like or list of lists\n",
    "        Feature matrix containing the independent variables.\n",
    "        Shape: (n_samples, n_features)\n",
    "    \n",
    "    y : array-like or list\n",
    "        Target vector containing the dependent variable.\n",
    "        Shape: (n_samples,)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    beta : numpy.ndarray\n",
    "        Coefficient vector including the intercept term and coefficients for each predictor.\n",
    "        Shape: (n_features + 1,)\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Conver inout to numpy (in case they are dataframes..)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Add intercept\n",
    "    ones = np.ones((X.shape[0], 1))  # vector of ones\n",
    "    X = np.concatenate((ones, X), axis =1)\n",
    "\n",
    "    #Compute the elements of the normal equations\n",
    "    #     A = (X'X)**(-1) \n",
    "    #     B = X'Y\n",
    "    #  beta = A* B is then the coefficient vector\n",
    "\n",
    "    A = np.linalg.inv(( X.T.dot(X)))\n",
    "    B = X.T.dot(y)\n",
    "\n",
    "    beta = A.dot(B)\n",
    "\n",
    "    return(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In NumPy, the * operator performs element-wise multiplication, not matrix multiplication.\n",
    "To perform matrix multiplication, use the .dot() method or the @ operator.\n",
    "\n",
    "\n",
    "`A.dot(B)`:  Correct way to perform matrix multiplication in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_new, beta):\n",
    "    \n",
    "    # Convert input to numpy array\n",
    "    X_new = np.array(X_new)\n",
    "\n",
    "    # Add intercept term\n",
    "    ones = np.ones((X_new.shape[0]),1 )\n",
    "    X_new = np.concat((ones, X_new), axis = 1)\n",
    "\n",
    "    # Calculate prediction \n",
    "\n",
    "    y_pred = X_new.dot(beta)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible follow up question would be **How would you implement linear \n",
    "regression using gradient descent instead of the normal equation?** \n",
    "\n",
    "This gradient approach is especially useful when dealing with a large number of \n",
    "features or when the matrix inversion in the normal equation becomes computationally \n",
    "expensive. Gradient descent works by iteratively adjusting the coefficients to minimize the cost function, typically the Mean Squared Error (MSE) for linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts of Gradient Descent for Linear Regression\n",
    "\n",
    "#### 3. Cost Function\n",
    "The cost function measures how well the model's predictions match the actual data. For linear regression, the cost function is the Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ m $ is the number of training examples.\n",
    "- $ h_{\\theta}(x^{(i)}) $ is the predicted value for the $ i $-th sample.\n",
    "- $ y^{(i)} $ is the actual value for the $ i $-th sample.\n",
    "\n",
    "The goal of gradient descent is to find the values of $ \\theta $ that minimize $ J(\\theta) \\).\n",
    "\n",
    "#### 4. Gradient Descent Algorithm\n",
    "Gradient Descent is an iterative optimization algorithm that updates the coefficients in the direction of the negative gradient of the cost function:\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\theta_j $ is the $ j $-th parameter.\n",
    "- $ \\alpha $ is the learning rate, controlling the step size.\n",
    "- $ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} $ is the partial derivative of the cost function with respect to $ \\theta_j $.\n",
    "\n",
    "#### 5. Gradient Calculation\n",
    "For linear regression, the gradient of the cost function with respect to each parameter $ \\theta_j $ is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ x_j^{(i)} $ is the value of the $ j $-th feature for the $ i $-th sample.\n",
    "\n",
    "#### 6. Update Rule\n",
    "The update rule for each coefficient in the gradient descent algorithm is:\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "This update rule is applied iteratively for all coefficients until convergence.\n",
    "\n",
    "#### 7. Learning Rate\n",
    "The learning rate $ \\alpha $ controls the size of the steps taken towards the minimum of the cost function. Choosing the right learning rate is crucial:\n",
    "- **Too small:** The algorithm will take too long to converge.\n",
    "- **Too large:** The algorithm may overshoot the minimum or even diverge.\n",
    "\n",
    "#### 8. Convergence\n",
    "The gradient descent algorithm converges when the cost function $ J(\\theta) $ reaches its minimum value. This can be monitored by checking the change in cost over iterations or by setting a maximum number of iterations.\n",
    "\n",
    "#### 9. Variants of Gradient Descent\n",
    "- **Batch Gradient Descent:** Uses all training examples to compute the gradient.\n",
    "- **Stochastic Gradient Descent (SGD):** Uses one training example at a time to compute the gradient, which can be faster but introduces more noise in the updates.\n",
    "- **Mini-batch Gradient Descent:** Uses a small subset (mini-batch) of the training examples to compute the gradient, balancing the efficiency and stability of the updates.\n",
    "\n",
    "#### 10. Summary\n",
    "Gradient Descent is a powerful algorithm for optimizing linear regression models, especially when dealing with large datasets. By iteratively updating the coefficients in the direction of the negative gradient of the cost function, it finds the optimal parameters that minimize the error between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So let's write these beast\n",
    "\n",
    "def linear_regression_gradient_descent(X, y, alpha=0.01, n_iterations=1000):\n",
    "    # alpha is the learning rate`\n",
    "    # Convert input to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Number of training examples and features\n",
    "    m = X.shape[0]  # Number of samples\n",
    "    n = X.shape[1]  # Number of features\n",
    "\n",
    "    # Add intercept\n",
    "    ones = np.ones((m, 1))  # vector of ones\n",
    "    X = np.concatenate((ones, X), axis =1)\n",
    "\n",
    "    # Initialize theta (coefficient vector) with zeros\n",
    "    beta = np.zeros(n+1)\n",
    "\n",
    "    # Initialize cost function (optional)\n",
    "    cost_history = []\n",
    "\n",
    "    ###########################################################################\n",
    "    # Gradient Descent\n",
    "\n",
    "    for iter in range(n_iterations):\n",
    "\n",
    "        y_pred = X.dot(beta)               # Calculate predictions\n",
    "        error = y_pred - y                  # Calculate errors\n",
    "        gradients = (1/m) *  np.dot(X.T, error) # Calculate gradients\n",
    "        beta = beta - alpha * gradients   # Update rule\n",
    "\n",
    "        cost_history.append( (1/(2*m)) * np.sum(error**2)) # Optional: update cost_history \n",
    "\n",
    "    return beta, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression.\n",
    "\n",
    "The logistic regression model arises from the desire to model the posterior \n",
    "probabilities of the K classes via linear functions in x, while at the same time\n",
    "ensuring that they sum to one and remain in [0,1].\n",
    "\n",
    "The **sigmoid function** is maps any real-valued number into a value between 0 \n",
    "and 1, making it suitable for modeling probabilities:\n",
    "\n",
    "$$   \\sigma(z) = \\frac{1}{1+ e^(-z)}  $$\n",
    "\n",
    "where $ z = \\beta_0 + \\beta X$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, alpha=0.01, n_iterations=1000):\n",
    "    # alpha is the learning rate`\n",
    "    # Convert input to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Number of training examples and features\n",
    "    m = X.shape[0]  # Number of samples\n",
    "    n = X.shape[1]  # Number of features\n",
    "\n",
    "    # Add intercept\n",
    "    ones = np.ones((m, 1))  # vector of ones\n",
    "    X = np.concatenate((ones, X), axis =1)\n",
    "\n",
    "    # Initialize theta (coefficient vector) with zeros\n",
    "    beta = np.zeros(n+1)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Gradient Descent\n",
    "    ###########################################################################\n",
    "\n",
    "    for iter in range(n_iterations):\n",
    "        \n",
    "        z = X.dot(beta)\n",
    "        y_pred = 1/(1 + np.exp(-z))              # Calculate predictions\n",
    "        error = y_pred - y                  # Calculate errors\n",
    "        gradients = (1/m) *  np.dot(X.T,error) # Calculate gradients\n",
    "        beta = beta - alpha * gradients   # Update rule\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearModels:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "        self.n = None\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        z = X.dot(self.beta)\n",
    "        prob = 1/(1 + np.exp(-z))\n",
    "        return prob\n",
    "\n",
    "    def fit(self, X_train, y_train, type = 'linear', alpha=0.01,\n",
    "                    min_cost = 1e-10,  max_iter=1000):\n",
    "\n",
    "        \"\"\"\n",
    "        The implementations based on gradient descent for linear and logistic \n",
    "        regression are almost identical. The only difference is the computation of \n",
    "        y_pred. This code makes this clear, generalizing the linear regression \n",
    "        function to include a new parameter, 'type':\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature matrix, shape (n_samples, n_features).\n",
    "        \n",
    "        y : array-like\n",
    "            Target vector, shape (n_samples,).\n",
    "        \n",
    "        type : string, optional\n",
    "            Either 'linear' or 'logistic'. Defines the type of regression performed.\n",
    "            Default is 'linear'.\n",
    "        \n",
    "        alpha : float, optional\n",
    "            Learning rate for gradient descent. Default is 0.01.\n",
    "        \n",
    "        max_iter : int, optional\n",
    "            Number of iterations for gradient descent. Default is 1000.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        beta : numpy.ndarray\n",
    "            Coefficient vector, shape (n_features + 1,).\n",
    "        \"\"\"\n",
    "        # alpha is the learning rate`\n",
    "        # Convert input to numpy arrays\n",
    "        X = np.array(X_train)\n",
    "        y = np.array(y_train)\n",
    "\n",
    "        # Number of training examples and features\n",
    "        m = X.shape[0]  # Number of samples \n",
    "        self.n = X.shape[1]  # Number of features (without intercept)\n",
    "\n",
    "        # Add intercept\n",
    "        ones = np.ones((m, 1))  # vector of ones\n",
    "        X = np.concatenate((ones, X), axis =1)\n",
    "\n",
    "        # Initialize beta (coefficient vector) with zeros\n",
    "        self.beta = np.zeros(self.n+1)\n",
    "\n",
    "        # Initialize cost function (optional)\n",
    "        cost =np.inf\n",
    "        iter = 0\n",
    "        ###########################################################################\n",
    "        # Gradient Descent\n",
    "        ###########################################################################\n",
    "\n",
    "        while iter <= max_iter and cost > min_cost:\n",
    "            iter +=1\n",
    "            if type == 'linear':\n",
    "                y_pred = X.dot(self.beta)  \n",
    "            elif type == 'logistic':\n",
    "                y_pred = self.sigmoid(X) # this is actually the probability of y = 1\n",
    "            else:\n",
    "                raise ValueError('Type must be either linear or logistic') \n",
    "\n",
    "            # Calculate predictions\n",
    "            error = y_pred - y                  # Calculate errors\n",
    "            gradients = (1/m) *  np.dot(X.T,error) # Calculate gradients\n",
    "            self.beta = self.beta - alpha * gradients   # Update rule\n",
    "\n",
    "            if type == 'linear':\n",
    "                # For linear regression, the cost function is Mean Squared Error (MSE)\n",
    "                cost = (1/(2*m)) * np.sum(error**2) \n",
    "            else:\n",
    "                # For logistic regression, the cost function is the negative log-likelihood\n",
    "                cost = (-1 / m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "            \n",
    "        return self.beta\n",
    "\n",
    "    def predict(self, X_test, type = 'linear', prob_threshold = 0.5):\n",
    "        \n",
    "        X = np.array(X_test)\n",
    "        if self.n != X.shape[1]:\n",
    "            raise ValueError('The number of features in the test data does not correspond to the number of regressors in the training data.')\n",
    "        m = X.shape[0]  # Number of samples \n",
    "        ones = np.ones((m, 1)) \n",
    "        \n",
    "\n",
    "        if type == 'linear':\n",
    "\n",
    "           X = np.concatenate((ones, X), axis =1)\n",
    "           y_pred = X.dot(self.beta) \n",
    "                \n",
    "        elif type == 'logistic':\n",
    "            X = np.concatenate((ones, X), axis =1)\n",
    "            prob = self.sigmoid(X)\n",
    "            y_pred = np.where(prob > prob_threshold, 1, 0)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional notes on logistic regression:\n",
    "\n",
    "\n",
    "Question: How would you modify your logistic regression implementation to \n",
    "include L2 regularization?\n",
    "\n",
    "We can add a regularization term to the cost function to penalize large weights.\n",
    "\n",
    "    - write deep-dive.\n",
    "\n",
    "Question: Which metrics would you use to evaluate your logistic regression model,\n",
    "and how would you implement them?\n",
    "\n",
    "Discus accuracy metrics:\n",
    "\t•\tPrecision\n",
    "\t•\tRecall\n",
    "\t•\tF1 Score\n",
    "\t•\tConfusion Matrix\n",
    "\t•\tROC Curve and AUC\n",
    "\n",
    "To-do: write code\n",
    "\n",
    "\n",
    "What are the key assumptions of logistic regression, and how can you test them \n",
    "with your data?\n",
    "\n",
    "List assumptions such as:\n",
    "\t•\tLinearity of independent variables and log-odds.\n",
    "\t•\tIndependence of errors.\n",
    "\t•\tLack of multicollinearity.\n",
    "\t•\tLarge sample size.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J(\\boldsymbol{\\beta}) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}i) \\right] + \\frac{\\lambda}{2m} \\sum{j=1}^{n} \\beta_j^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comaprison/resume of logistic and linear regressions.\n",
    "\n",
    "\n",
    "| **Aspect**                     | **Linear Regression**                                                                                  | **Logistic Regression**                                                                                   |\n",
    "|---------------------------------|--------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| **Explanation**                | Predicts a continuous target variable $Y$ based on a linear relationship with features $X$.        | Predicts the probability of a binary outcome using the sigmoid function to constrain predictions between 0 and 1. |\n",
    "| **Mathematical Representation**| $ \\hat{Y} = \\beta_0 + \\sum_{j=1}^{n} \\beta_j X_j$ | $P(Y = 1) = \\frac{1}{1 + e^{-z}}, \\quad z = \\beta_0 + \\sum_{j=1}^{n} \\beta_j X_j $                |\n",
    "| **Loss Function with L2 Penalty** | $ J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\beta_j^2 $ | $ J(\\boldsymbol{\\beta}) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\beta_j^2 $ |\n",
    "| **Gradient with L2 Penalty**    | $ \\nabla_{\\beta_j} = -\\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i) X_{ij} + \\frac{\\lambda}{m} \\beta_j $ | $ \\nabla_{\\beta_j} = -\\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i) X_{ij} + \\frac{\\lambda}{m} \\beta_j $ |\n",
    "\n",
    "### Notes:\n",
    "1. **Loss Function Difference:** Linear regression uses Mean Squared Error (MSE) as the loss, while logistic regression uses Negative Log-Likelihood.\n",
    "2. **Gradient Formula Similarity:** Both models update their parameters using gradient descent, with the addition of the L2 penalty $ \\frac{\\lambda}{m} \\beta_j $.\n",
    "3. **Sigmoid Function in Logistic Regression:** This function transforms the linear combination of predictors into a probability constrained between 0 and 1, making logistic regression suitable for binary outcomes.​⬤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "#### Summary:\n",
    "\n",
    "* Precision: Focuses on the proportion of relevant instances (true positives) among the retrieved instances.\n",
    "* Recall: Measures the proportion of actual positives correctly identified.\n",
    "* F1 Score: A balance between precision and recall.\n",
    "* Confusion Matrix: Provides a comprehensive view of the model’s performance.\n",
    "* ROC Curve and AUC: Useful for evaluating the trade-off between recall and false positives at different thresholds, with AUC providing a summary measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Precision\n",
    "\n",
    "Precision measures the proportion of **true positives predictions** out of all positive prediction made\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$$\n",
    "\n",
    "It is important to look at precision when the cost of false positives is high (eg\n",
    "spam detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(y_true, y_pred):\n",
    "\n",
    "    true_positive = np.sum((y_true==1) & (y_pred==1))\n",
    "    false_positive = np.sum((y_true==0) & (y_pred==1) )\n",
    "\n",
    "    return true_positive/false_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "\n",
    "Recall measures the proportion of **true positive predictions** out of all \n",
    "actual positive cases. \n",
    "\n",
    "$$ \\text{Recal} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$$\n",
    "\n",
    "It is import to look at recall when it is critical to capture as many positives as possible, such as in disease detection (missing an actual positive case is \n",
    "dangerous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(y_true, y_pred):\n",
    "\n",
    "    true_positive = np.sum( (y_true == 1) & (y_pred == 1) )\n",
    "    false_negative = np.sum( (y_true == 1) & (y_pred == 0) )\n",
    "\n",
    "    return true_positive/(true_positive + false_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "The F1 Score is the **harmonic mean** of precision and recall. \n",
    "\n",
    "$$ \\text{F1 Score} = 2\\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}  $$\n",
    "\n",
    "The metric is usefull when we need to balance the trade-off between precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve and AUC\n",
    "\n",
    "The ROC curve is a plot that show the trade-off between **true positive rate (recall)** and **false positive rate (FPR)**\n",
    "\n",
    "THE AUC (Area Under the Curve) represents the area under the ROC curve and is a single number that summarizes the model's ability to distinguish classess: the higher the AUC, the better the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
