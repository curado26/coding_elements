{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize constructor with the following objects:\n",
    "        self.max_depth = 100\n",
    "        self.tree = None # To store the fitted decision tree\n",
    "\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        \"\"\"\n",
    "        Compute the gini index of a given set of labels.\n",
    "        Parameters:\n",
    "            y: array-like.\n",
    "                The response variable that you are trying to predict\n",
    "        Returns\n",
    "            float:\n",
    "                The Gini Index for a given y.\n",
    "        \"\"\"\n",
    "        gini = 1\n",
    "        classes = np.unique(y)\n",
    "        for c in classes:\n",
    "            pi_c =  len(y[y==c])/len(y)\n",
    "            gini -= pi_c**2\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def find_feature_type(self, feature):\n",
    "        if feature.dtype == 'object' or (feature.dtype == np.int_ and len(np.unique(feature)) < 5):\n",
    "            return 'categorical'\n",
    "        else:\n",
    "            return 'continuous'\n",
    "\n",
    "    def find_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best feature-threshold to split a given node.\n",
    "\n",
    "        Parameters:\n",
    "            X: array-like\n",
    "                Set of explanatory features\n",
    "            y: array-like\n",
    "                Response variable.\n",
    "\n",
    "        Returns:\n",
    "            selected_features: int\n",
    "                The feature that provides the best split (that is, that \n",
    "                minimizes the Gini Index)\n",
    "            selected_threshold: float\n",
    "                The thresgold that provides the best split\n",
    "        \"\"\"\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        gini = float('inf')\n",
    "        selected_feature = None\n",
    "        selected_threshold = None\n",
    "\n",
    "        for j in range(0, n_features):\n",
    "            feature = X[:,j]\n",
    "            thresholds = np.sort(np.unique(feature), axis = 0)  #sort:\n",
    "            \n",
    "            feature_type = self.find_feature_type(feature)\n",
    "\n",
    "            for t in thresholds:\n",
    "\n",
    "                if feature_type == \"continuous\":\n",
    "                    y_left  = y[ feature  < t ]\n",
    "                    y_right = y[ feature >= t ]\n",
    "                elif feature_type ==\"categorical\":\n",
    "                    y_left  = y[ feature == t ]\n",
    "                    y_right = y[ feature != t ]\n",
    "                # Continue to next threshold if one of the splits is empty\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                weighted_gini = ( self.gini_index(y=y_left)*len(y_left) +\n",
    "                                  self.gini_index(y=y_right)*len(y_right) )/len(y)\n",
    "\n",
    "                if weighted_gini < gini:\n",
    "                    gini = weighted_gini\n",
    "                    selected_feature = j \n",
    "                    selected_threshold = t\n",
    "\n",
    "        return selected_feature, selected_threshold\n",
    "\n",
    "\n",
    "    def make_split(self, X, y, selected_feature, selected_threshold):\n",
    "        \"\"\" \n",
    "        Split the data into left and right branches\n",
    "\n",
    "        Returns \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        left_mask = X[:,selected_feature] < selected_threshold\n",
    "        y_left, X_left = y[left_mask], X[left_mask,:]\n",
    "        y_right, X_right = y[~left_mask], X[~left_mask,:]\n",
    "\n",
    "        return X_left, y_left, X_right, y_right\n",
    "\n",
    "\n",
    "    def fit(self, X, y, max_depth=100, depth=0):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if depth == max_depth or len(y) < 2:\n",
    "            unique_classes, counts = np.unique(y, return_counts=True)\n",
    "            return unique_classes[np.argmax(counts)]\n",
    "        else: \n",
    "\n",
    "            # Find best [feature, threshold] for this node\n",
    "            selected_feature, selected_threshold = self.find_split(X, y)\n",
    "\n",
    "            # Split the data\n",
    "            X_left, y_left, X_right, y_right = self.make_split(X, y,\n",
    "                                            selected_feature, selected_threshold)\n",
    "               # If one of the splits is empty, return the most common class of the current node\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                unique_classes, counts = np.unique(y, return_counts=True)\n",
    "                return unique_classes[np.argmax(counts)]\n",
    "    \n",
    "        #RECURSION\n",
    "            left_subtree = self.fit(X_left,   y_left,  depth + 1)\n",
    "            right_subtree = self.fit(X_right, y_right, depth + 1)\n",
    "        # Return the current node with the left and right subtrees\n",
    "        \n",
    "         # Return the current node with the left and right subtrees\n",
    "        return {\n",
    "            'feature': selected_feature,\n",
    "            'threshold': selected_threshold,\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree\n",
    "        }\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        \"\"\"\n",
    "            Predict y class given the observations for the set of explanatory \n",
    "            featyres X\n",
    "            Parameters:\n",
    "                X_test: array-like\n",
    "                    New observations of the explanatory features\n",
    "                Returns\n",
    "                y_pred: array-like\n",
    "                    Predictions for y\n",
    "        \"\"\"\n",
    "        X = np.array(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class_2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mock_decision_tree_dataset.csv')\n",
    "tree = DecisionTree()\n",
    "tree.fit(X = df.drop('y', axis =1), y=df['y'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
