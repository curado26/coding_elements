{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Sample T-Test\n",
    "The one-sample t-test tests wether the mean of a sample differs significantly \n",
    "from a known or hypothesized population mean. It assumes the data is normally \n",
    "distributed.\n",
    "\n",
    "* $H_0$ is that the sample mean $\\bar{x}$ is equal to the population mean $\\mu$.\n",
    "* $H_1$:   $\\bar{x} \\neq \\mu$\n",
    "\n",
    "Test statistic:\n",
    "\n",
    "$$ t = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "class TTest:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t_stat = None\n",
    "        self.p_value = None\n",
    "    \n",
    "    def one_sample_t_test(self, sample: list, mu: float) -> float:\n",
    "        \"\"\"\n",
    "        Perform a one-sample t-test to check if the sample mean is significantly\n",
    "        different from the population mean\n",
    "\n",
    "        Parameters:\n",
    "            sample: array-like. \n",
    "                The sample data.\n",
    "            mu: float.\n",
    "                The population mean, \n",
    "\n",
    "        Returns:\n",
    "            t-stat: float.\n",
    "                The estimated t-statistic\n",
    "            p-value: float.\n",
    "                The estimated p-value for the t-test. This is the probability of \n",
    "                obtaining test results *at least as extreme* as the observed in\n",
    "                the data\n",
    "        \"\"\"\n",
    "\n",
    "        # GUarantee that sample is a numpy array\n",
    "        X = np.array(sample)\n",
    "\n",
    "        # Sample size n and degrees of freedom df\n",
    "        n = len(X)\n",
    "        df = n-1\n",
    "        \n",
    "        # Compute sample statistics \n",
    "        X_bar = sum(X)/n                  #Sample mean\n",
    "        X_std = (sum( (X-X_bar)**2 )/(n-1))**0.5 # Sample standard deviation\n",
    "\n",
    "        # t-statistic\n",
    "        self.t_stat = (X_bar - mu)/(X_std/(n**0.5))\n",
    "        \n",
    "        # Two-Tailed P-Value \n",
    "        self.p_value = 2 * (1 - stats.t.cdf( abs(self.t_stat, df))   )\n",
    "\n",
    "        return self.t_stat, self.p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "abs() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sample \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m2.8\u001b[39m, \u001b[38;5;241m3.5\u001b[39m, \u001b[38;5;241m3.1\u001b[39m, \u001b[38;5;241m2.9\u001b[39m, \u001b[38;5;241m3.0\u001b[39m]\n\u001b[1;32m      2\u001b[0m ttest \u001b[38;5;241m=\u001b[39m TTest()\n\u001b[0;32m----> 3\u001b[0m t_stat, p_val \u001b[38;5;241m=\u001b[39m \u001b[43mttest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_sample_t_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT-Statistic:\u001b[39m\u001b[38;5;124m\"\u001b[39m, t_stat)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP-Value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p_val)\n",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m, in \u001b[0;36mTTest.one_sample_t_test\u001b[0;34m(self, sample, mu)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_stat \u001b[38;5;241m=\u001b[39m (X_bar \u001b[38;5;241m-\u001b[39m mu)\u001b[38;5;241m/\u001b[39m(X_std\u001b[38;5;241m/\u001b[39m(n\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Two-Tailed P-Value \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m stats\u001b[38;5;241m.\u001b[39mt\u001b[38;5;241m.\u001b[39mcdf( \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_stat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m)   )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_stat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_value\n",
      "\u001b[0;31mTypeError\u001b[0m: abs() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "sample = [2.5, 3.0, 2.8, 3.5, 3.1, 2.9, 3.0]\n",
    "ttest = TTest()\n",
    "t_stat, p_val = ttest.one_sample_t_test(sample, mu=3.0)\n",
    "print(\"T-Statistic:\", t_stat)\n",
    "print(\"P-Value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Sample T-Test (t-test for independent samples)\n",
    "The two-sample t-test compares the means of two independent samples to determine \n",
    "if they come from populations with the same mean. It assumes that both samples \n",
    "are normally distributed and have equal variances.\n",
    "\n",
    "\n",
    "* $H_0$:  The means of the two samples are equal ($\\bar{x_1} = \\bar{x_2}$)\n",
    "* $H_1$:  ($\\bar{x_1} = \\bar{x_2}$)$\n",
    "\n",
    "Test statistic:\n",
    "\n",
    "$$ t = \\frac{\\bar{x_1}-\\bar{x_2}}{  \\sqrt{ \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} }  }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "class TTest:\n",
    "\n",
    "    \n",
    "    def two_sample_t_test(self, sample_1: list, sample_2: list) -> float:\n",
    "        \"\"\"\n",
    "        Perform a two-sample t-test to check if the sample mean is significantly\n",
    "        different from the population mean.\n",
    "        Assumption: both samples have the same variance.\n",
    "\n",
    "        Parameters:\n",
    "            sample_1: array-like. \n",
    "                The first sample data.\n",
    "            sample_2: array-like. \n",
    "                The second sample data.\n",
    "            mu: float.\n",
    "                The population mean, \n",
    "\n",
    "        Returns:\n",
    "            t-stat: float.\n",
    "                The estimated t-statistic\n",
    "            p-value: float.\n",
    "                The estimated p-value for the t-test. This is the probability of \n",
    "                obtaining test results *at least as extreme* as the observed in\n",
    "                the data.\n",
    "        \"\"\"\n",
    "\n",
    "        # GUarantee that sample is a numpy array\n",
    "        X1= np.array(sample_1)\n",
    "        X2= np.array(sample_2)\n",
    "\n",
    "        # Sample size n and degrees of freedom df\n",
    "        n1, n2 = len(X1), len(X2)\n",
    "        df = n1 + n2 -2\n",
    "        \n",
    "        # Compute sample statistics \n",
    "        X_bar1 = sum(X1)/n1                  #Sample mean\n",
    "        X_bar2 = sum(X2)/n2                  #Sample mean\n",
    "\n",
    "        X_std1 = (sum( (X1-X_bar1)**2 )/(n1-1))*0.5 # Sample standard deviation\n",
    "        X_std2 = (sum( (X2-X_bar2)**2 )/(n2-1))*0.5 # Sample standard deviation\n",
    "\n",
    "        # t-statistic\n",
    "        denominator = ( X_std1**2/n1 + X_std2**2/n2 )**0.5\n",
    "        self.t_stat = (X_bar1 - X_bar2)/denominator\n",
    "        # p-value\n",
    "        self.p_value = 2 * (1 - stats.t.cdf( abs(self.t_stat), df)   )\n",
    "\n",
    "        return self.t_stat, self.p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 4.869896747011, P-Value: 0.0012401343566106338\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "sample1 = [75, 78, 74, 72, 77]\n",
    "sample2 = [68, 65, 70, 67, 69]\n",
    "\n",
    "# Perform the t-test\n",
    "ttest = TTest()\n",
    "t_stat, p_val = ttest.two_sample_t_test(sample1, sample2)\n",
    "print(f\"T-Statistic: {t_stat}, P-Value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova (Analysis of Variance)\n",
    "See docs: https://docs.google.com/document/d/13b2W1HfUgijqNlsQ_3fQgJ6pIyJTJ5UdjuOSy2BXNW8/edit?usp=sharing\n",
    "\n",
    "ANOVA is used to determine if there are any statistically significant difference\n",
    "between the meaans of three or more groups. It compares the \n",
    "**variance between groups** with the **variance within groups** to check if at \n",
    "least one group's mean is different\n",
    "\n",
    "* $H_0$: All groups means are equal: $\\bar{x_1} = \\bar{x_2} = ...= \\bar{x_n}$\n",
    "* $H_1$: Att least one group mean is differente.\n",
    "\n",
    "\n",
    "The test statistic is the F-Statistic $$ \\frac{SSB/(k-1)}{SSW/(n-k)}   $$\n",
    "\n",
    "where $k$ is the number of groups, $n$ is the total number of observations \n",
    "across  all groups.  \n",
    "\n",
    "$SSB$ is the **Between-groups sum of squares**,  \n",
    "            $$ SSB = \\sum_{i=1:k} n_i (\\bar{x_i} -\\bar{x})^2  $$ \n",
    "\n",
    "where\n",
    " * $n_i$ is the number of observations in group $i$ \n",
    " * $\\bar{x_i}$: mean of group $i$ \n",
    " * $\\bar{x}$: overall mean across all groups\n",
    "\n",
    " and  SSW is the **Within groups sum of squares**,\n",
    "        $$ SSW = \\sum_{i=1:k} \\sum_{j \\text{in group i}} (x_{ij} - \\bar{x_i})^2   $$\n",
    "    \n",
    "where $x_{ij}$ is observation $j$ in group $i$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# The implementation comes from chatGPT. It is currently to hard for me. I suggest you skip it.\n",
    "class ANOVA:\n",
    "    def __init__(self):\n",
    "        self.f_statistic = None\n",
    "        self.p_value = None\n",
    "\n",
    "    def one_way_anova(self, *groups):\n",
    "        \"\"\"\n",
    "        Perform one-way ANOVA to test whether the means of multiple groups are equal.\n",
    "\n",
    "        Parameters:\n",
    "        *groups : array-like\n",
    "            Each argument represents a group of sample data.\n",
    "\n",
    "        Returns:\n",
    "        f_statistic : float\n",
    "            The computed F-statistic.\n",
    "        p_value : float\n",
    "            The p-value for the ANOVA test.\n",
    "        \"\"\"\n",
    "        # Calculate the total number of observations and number of groups\n",
    "        n_total = sum([len(group) for group in groups])\n",
    "        k = len(groups)\n",
    "\n",
    "        # Calculate the grand mean\n",
    "        grand_mean = np.mean([x for group in groups for x in group])\n",
    "\n",
    "        # Calculate Between-group sum of squares (SSB)\n",
    "        ssb = sum([len(group) * (np.mean(group) - grand_mean) ** 2 for group in groups])\n",
    "\n",
    "        # Calculate Within-group sum of squares (SSW)\n",
    "        ssw = sum([sum((x - np.mean(group)) ** 2 for x in group) for group in groups])\n",
    "\n",
    "        # Degrees of freedom\n",
    "        df_between = k - 1\n",
    "        df_within = n_total - k\n",
    "\n",
    "        # Mean squares\n",
    "        ms_between = ssb / df_between\n",
    "        ms_within = ssw / df_within\n",
    "\n",
    "        # F-statistic\n",
    "        self.f_statistic = ms_between / ms_within\n",
    "\n",
    "        # P-value (using F-distribution)\n",
    "        self.p_value = 1 - stats.f.cdf(self.f_statistic, df_between, df_within)\n",
    "\n",
    "        return self.f_statistic, self.p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Test \n",
    "\n",
    "The Chi-squared tests are a family of statistial tests used for categorical data\n",
    "analysis. They evvaluate the **association** or **independence** between categorical\n",
    "variables, or how well the observed data fits an expected distribution.\n",
    "\n",
    "There are 3 main types of Chi-squared tests, but since 2 are very similar, I'm \n",
    "gonna treat it as a subcase.\n",
    "\n",
    "#### Test Statististic\n",
    "\n",
    "All Chi-squared test statistics are the given by:\n",
    "\n",
    "$$  \\chi^2 = \\sum \\frac{(O_i-E_i)^2}{E_i} $$\n",
    "\n",
    "where \n",
    "* $O_i$ is the Observed frequency (from sample)\n",
    "* $E_i$ is the Expected frequency \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Googness of Fit\n",
    "\n",
    "Determines if a sample matches a specific distribution. It is used when there is \n",
    "**one categorical variable** and we want to see if the observed data gits a know\n",
    "distribution. For example, we can test if a dice is fair.\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "* $H_0$: The observed frequencies follow the specified distribution\n",
    "* $H_1$: The obsered frequencies **do not** follow the specified distribution\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChiSquaredTests:\n",
    "    def chi_squared_goodness_of_fit(self, observed, expected):\n",
    "        \"\"\"\n",
    "        Perform a chi-squared goodness of fit test.\n",
    "        -----------\n",
    "        Parameters\n",
    "        -----------\n",
    "        observed: array-like.\n",
    "            The observed frequencies.\n",
    "        expected: array-like,\n",
    "            The expected frequencie\n",
    "        ----------\n",
    "        Returns\n",
    "        ----------\n",
    "        chi2_stat: float\n",
    "            The computed chi-squared statistic.\n",
    "        p-value: float\n",
    "            The estimated p-value for the test. This is the probability of \n",
    "            obtaining test results *at least as extreme* as the observed in\n",
    "            the data.\n",
    "        \"\"\"\n",
    "\n",
    "        #Guarantees that data is a numpy array\n",
    "        observed = np.array(observed)\n",
    "        expected = np.array(expected)\n",
    "\n",
    "        # Compute test statistic and degrees of freedom (df)\n",
    "        chi2_stat =  sum( ((observed - expected)**2)/expected )\n",
    "        df = len(observed) -1 \n",
    "\n",
    "        p_value = 1 - stats.chi2.cdf(chi2_stat, df  )\n",
    "\n",
    "        return chi2_stat, p_value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 5.12\n",
      "P-Value: 0.401\n"
     ]
    }
   ],
   "source": [
    "# Observed frequencies of a dice roll\n",
    "observed = [16, 18, 16, 14, 12, 24]\n",
    "\n",
    "# Expected frequencies if the die is fair\n",
    "expected = [100 / 6] * 6\n",
    "\n",
    "# Instantiate the ChiSquaredTest class\n",
    "chi_test = ChiSquaredTests()\n",
    "\n",
    "# Perform the chi-squared goodness of fit test\n",
    "chi2_stat, p_value = chi_test.chi_squared_goodness_of_fit(observed, expected)\n",
    "\n",
    "print(f\"Chi-Squared Statistic: {chi2_stat.round(3)}\")\n",
    "print(f\"P-Value: {p_value.round(3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Since p-value is high, we do not reject the null hypothesis of a fair dice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on the Chi-Squared Distribution\n",
    "\n",
    "Left, pdf.  Right, cdf.\n",
    "\n",
    "<img src=\"images/chi_squared_pdf.png\" alt=\"left\" width=\"450\"/>\n",
    "\n",
    "<img src=\"images/chi_squared_cdf.png\" alt=\"right\" width=\"450\"/>\n",
    "\n",
    "\n",
    "Notice that in the computation of the $\\Chi^2$ test statistic, we don't take the abolute value nor multiplu it by two, in the way we do in the case of the t-test.\n",
    "\n",
    "To understand this, first notice that the $\\Chi^2$ take only non-negative values: the distribution is inherently one-side. Indeed, the $  \\chi^2 = \\sum \\frac{(O_i-E_i)^2}{E_i} $ formula implies that the result is always non-negative.  Therefore, we calculate \n",
    "the p-value of the $\\Chi^2$ test using the **right-tail area only**, that is: \n",
    "\n",
    "$$ \\text{p-value} = 1 - CDF(\\Chi^2, df) $$\n",
    "\n",
    "The **t-statistic**, on the other hand, can be **positive or negative**. Therefore, \n",
    "we need to consider the possibility of extreme values on **both sides** of the \n",
    "distribution. For a ** two-tailed t-test**, we calculate the p-value such that:\n",
    "\n",
    "$$ \\text{p-value} =2 * (1 - CDF(|t|), df)) $$\n",
    "\n",
    "Since $(1 - CDF(|t|), df)$ gives the right-tail probability of observing a value\n",
    "greater that $|t|$, we need to multiply it by to to account for the left side\n",
    "\n",
    "\n",
    "| **Aspect**                 | **T-Test**                                     | **Chi-Squared Test**                             |\n",
    "|----------------------------|------------------------------------------------|--------------------------------------------------|\n",
    "| **Nature of Test**         | Two-tailed test (both positive and negative)   | One-sided test (only positive deviations)        |\n",
    "| **Statistic Calculation**  | Can be positive or negative                    | Always non-negative (squared differences)        |\n",
    "| **Use of Absolute Value**  | Takes absolute value for two-tailed tests      | Not required, as χ² is inherently non-negative   |\n",
    "| **Multiplying by 2**       | Multiplied by 2 for two-tailed tests           | Not multiplied by 2 (only right-tail is relevant)|\n",
    "| **P-Value Calculation**    | Uses both tails of the t-distribution          | Uses right-tail of the Chi-Squared distribution  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
